{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display column names of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers for Market 1:\n",
      "File: Market 1 Customers.json\n",
      "Customer ID\n",
      "Last Used Platform\n",
      "Is Blocked\n",
      "Created At\n",
      "Language\n",
      "Outstanding Amount\n",
      "Loyalty Points\n",
      "Number of employees\n",
      "----------------------------------------\n",
      "File: Market 1 Orders.csv\n",
      "Order ID\n",
      "Order Status\n",
      "Category Name\n",
      "SKU\n",
      "Customization Group\n",
      "Customization Option\n",
      "Quantity\n",
      "Unit Price\n",
      "Cost Price\n",
      "Total Cost Price\n",
      "Total Price\n",
      "Order Total\n",
      "Sub Total\n",
      "Tax\n",
      "Delivery Charge\n",
      "Tip\n",
      "Discount\n",
      "Remaining Balance\n",
      "Payment Method\n",
      "Additional Charge\n",
      "Taxable Amount\n",
      "Transaction ID\n",
      "Currency Symbol\n",
      "Transaction Status\n",
      "Promo Code\n",
      "Customer ID\n",
      "Merchant ID\n",
      "Description\n",
      "Distance (in km)\n",
      "Order Time\n",
      "Pickup Time\n",
      "Delivery Time\n",
      "Ratings\n",
      "Reviews\n",
      "Merchant Earning\n",
      "Commission Amount\n",
      "Commission Payout Status\n",
      "Order Preparation Time\n",
      "Debt Amount\n",
      "Redeemed Loyalty Points\n",
      "Consumed Loyalty Points\n",
      "Cancellation Reason\n",
      "Flat Discount\n",
      "Checkout Template Name\n",
      "Checkout Template Value\n",
      "----------------------------------------\n",
      "File: Market 1 Deliveries.csv\n",
      "Task_ID\n",
      "Order_ID\n",
      "Relationship\n",
      "Team_Name\n",
      "Task_Type\n",
      "Notes\n",
      "Agent_ID\n",
      "Agent_Name\n",
      "Distance(m)\n",
      "Total_Time_Taken(min)\n",
      "Task_Status\n",
      "Ref_Images\n",
      "Rating\n",
      "Review\n",
      "Latitude\n",
      "Longitude\n",
      "Tags\n",
      "Promo_Applied\n",
      "Custom_Template_ID\n",
      "Task_Details_QTY\n",
      "Task_Details_AMOUNT\n",
      "Special_Instructions\n",
      "Tip\n",
      "Delivery_Charges\n",
      "Discount\n",
      "Subtotal\n",
      "Payment_Type\n",
      "Task_Category\n",
      "Earning\n",
      "Pricing\n",
      "Unnamed: 30\n",
      "Unnamed: 31\n",
      "----------------------------------------\n",
      "\n",
      "Column headers for Market 2:\n",
      "File: Market 2 Customers.json\n",
      "Customer ID\n",
      "Last Used Platform\n",
      "Is Blocked\n",
      "Created At\n",
      "Language\n",
      "Outstanding Amount\n",
      "Loyalty Points\n",
      "Number of Employees\n",
      "----------------------------------------\n",
      "File: Market 2 Orders.csv\n",
      "Order ID\n",
      "Order Status\n",
      "Category Name\n",
      "SKU\n",
      "Customization Group\n",
      "Customization Option\n",
      "Quantity\n",
      "Unit Price\n",
      "Cost Price\n",
      "Total Cost Price\n",
      "Total Price\n",
      "Order Total\n",
      "Sub Total\n",
      "Tax\n",
      "Delivery Charge\n",
      "Tip\n",
      "Discount\n",
      "Remaining Balance\n",
      "Payment Method\n",
      "Additional Charge\n",
      "Taxable Amount\n",
      "Transaction ID\n",
      "Currency Symbol\n",
      "Transaction Status\n",
      "Promo Code\n",
      "Customer ID\n",
      "Merchant ID\n",
      "Description\n",
      "Distance (in km)\n",
      "Order Time\n",
      "Pickup Time\n",
      "Delivery Time\n",
      "Ratings\n",
      "Reviews\n",
      "Merchant Earning\n",
      "Commission Amount\n",
      "Commission Payout Status\n",
      "Order Preparation Time\n",
      "Redeemed Loyalty Points\n",
      "Consumed Loyalty Points\n",
      "Cancellation Reason\n",
      "Flat Discount\n",
      "Checkout Template Name\n",
      "Checkout Template Value\n",
      "----------------------------------------\n",
      "File: Market 2 Deliveries.csv\n",
      "Task_ID\n",
      "Order_ID\n",
      "Relationship\n",
      "Team_Name\n",
      "Task_Type\n",
      "Notes\n",
      "Agent_ID\n",
      "Distance(m)\n",
      "Total_Time_Taken(min)\n",
      "Task_Status\n",
      "Ref_Images\n",
      "Rating\n",
      "Review\n",
      "Latitude\n",
      "Longitude\n",
      "Tags\n",
      "Promo_Applied\n",
      "Custom_Template_ID\n",
      "Task_Details_QTY\n",
      "Task_Details_AMOUNT\n",
      "Special_Instructions\n",
      "Tip\n",
      "Delivery_Charges\n",
      "Discount\n",
      "Subtotal\n",
      "Payment_Type\n",
      "Task_Category\n",
      "Earning\n",
      "Pricing\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"Market 1 Customers.json\",\n",
    "    \"Market 2 Customers.json\",\n",
    "    \"Market 1 Orders.csv\",\n",
    "    \"Market 2 Orders.csv\",\n",
    "    \"Market 1 Deliveries.csv\",\n",
    "    \"Market 2 Deliveries.csv\"\n",
    "]\n",
    "\n",
    "market1_columns = {}\n",
    "market2_columns = {}\n",
    "\n",
    "# Read the column headers from each file and store them in the respective dictionaries\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(file_name)\n",
    "    try:\n",
    "        if file_name.lower().endswith(\".json\"):\n",
    "            df = pd.read_json(file_path)\n",
    "        elif file_name.lower().endswith(\".csv\"):\n",
    "            # Explicitly set low_memory=False to avoid DtypeWarning\n",
    "            df = pd.read_csv(file_path, low_memory=False)\n",
    "        else:\n",
    "            print(f\"Unsupported file format for {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Store column headers in the respective dictionaries based on market\n",
    "        if \"Market 1\" in file_name:\n",
    "            market1_columns[file_name] = df.columns.tolist()\n",
    "        elif \"Market 2\" in file_name:\n",
    "            market2_columns[file_name] = df.columns.tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found.\")\n",
    "\n",
    "# Display the column headers for both markets\n",
    "print(\"Column headers for Market 1:\")\n",
    "for file_name, headers in market1_columns.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    for header in headers:\n",
    "        print(header)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nColumn headers for Market 2:\")\n",
    "for file_name, headers in market2_columns.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    for header in headers:\n",
    "        print(header)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers for both markets are stored in 'market_column_headers.xlsx'\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"Market 1 Customers.json\",\n",
    "    \"Market 2 Customers.json\",\n",
    "    \"Market 1 Orders.csv\",\n",
    "    \"Market 2 Orders.csv\",\n",
    "    \"Market 1 Deliveries.csv\",\n",
    "    \"Market 2 Deliveries.csv\"\n",
    "]\n",
    "\n",
    "market1_columns = []\n",
    "market2_columns = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(file_name)\n",
    "    try:\n",
    "        if file_name.lower().endswith(\".json\"):\n",
    "            df = pd.read_json(file_path)\n",
    "        elif file_name.lower().endswith(\".csv\"):\n",
    "            # Explicitly set low_memory=False to avoid DtypeWarning\n",
    "            df = pd.read_csv(file_path, low_memory=False)\n",
    "        else:\n",
    "            print(f\"Unsupported file format for {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Store column headers in the respective lists based on market\n",
    "        if \"Market 1\" in file_name:\n",
    "            market1_columns.append([file_name] + df.columns.tolist())\n",
    "        elif \"Market 2\" in file_name:\n",
    "            market2_columns.append([file_name] + df.columns.tolist())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found.\")\n",
    "\n",
    "# Combine column headers for both markets\n",
    "combined_columns = market1_columns + market2_columns\n",
    "\n",
    "# Write the column headers to an Excel file\n",
    "with pd.ExcelWriter(\"market_column_headers.xlsx\") as writer:\n",
    "    pd.DataFrame(combined_columns).to_excel(writer, sheet_name='Market', index=False, header=False)\n",
    "\n",
    "print(\"Column headers for both markets are stored in 'market_column_headers.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined customer data is saved in 'combined_customer_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define the list of file names for customer datasets\n",
    "customer_files = [\n",
    "    \"Market 1 Customers.json\",\n",
    "    \"Market 2 Customers.json\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes for each customer dataset\n",
    "customer_dataframes = []\n",
    "\n",
    "# Read data from each customer dataset and append to the list\n",
    "for file_name in customer_files:\n",
    "    file_path = os.path.join(file_name)\n",
    "    try:\n",
    "        if file_name.lower().endswith(\".json\"):\n",
    "            df = pd.read_json(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format for {file_name}\")\n",
    "            continue\n",
    "        customer_dataframes.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found.\")\n",
    "\n",
    "# Concatenate the dataframes vertically\n",
    "combined_customer_data = pd.concat(customer_dataframes, ignore_index=True)\n",
    "\n",
    "    \n",
    "# Save consolidated data to the output subfolder\n",
    "output_file = os.path.join(\"combined_customer_data.csv\")\n",
    "\n",
    "combined_customer_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined customer data is saved in '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified customer data is saved in 'transformed_data\\customers.csv'\n"
     ]
    }
   ],
   "source": [
    "# Read the combined customer data from the CSV file\n",
    "input_file = \"combined_customer_data.csv\"\n",
    "customers = pd.read_csv(input_file)\n",
    "\n",
    "# Copy values from \"Number of Employees\" to \"Number of employees\" and drop the original column\n",
    "if \"Number of Employees\" in customers.columns:\n",
    "    customers[\"Number of employees\"] = customers[\"Number of Employees\"]\n",
    "    customers.drop(columns=[\"Number of Employees\"], inplace=True)\n",
    "\n",
    "# Define the output folder\n",
    "output_folder = \"transformed_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file in the output folder\n",
    "output_file = os.path.join(output_folder, \"customers.csv\")\n",
    "customers.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Modified customer data is saved in '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset with standardized column names is saved in 'transformed_data\\orders.csv'\n"
     ]
    }
   ],
   "source": [
    "def standardize_column_names(df):\n",
    "    \"\"\"Standardizes column names in a DataFrame.\"\"\"\n",
    "    standardized_names = {}\n",
    "\n",
    "    for original_column in df.columns:\n",
    "        new_column = original_column.lower().replace(\" \", \"_\")\n",
    "        standardized_names[new_column] = original_column\n",
    "\n",
    "    df.rename(columns=standardized_names, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Read both datasets\n",
    "market1_orders = pd.read_csv(\"Market 1 Orders.csv\")\n",
    "market2_orders = pd.read_csv(\"Market 2 Orders.csv\")\n",
    "\n",
    "# Standardize column names\n",
    "market1_orders = standardize_column_names(market1_orders)\n",
    "market2_orders = standardize_column_names(market2_orders)\n",
    "\n",
    "# Check for missing columns in each dataset\n",
    "missing_columns_market1 = set(market2_orders.columns) - set(market1_orders.columns)\n",
    "missing_columns_market2 = set(market1_orders.columns) - set(market2_orders.columns)\n",
    "\n",
    "# Add missing columns with null values and ensure data consistency\n",
    "for column in missing_columns_market1:\n",
    "    market1_orders[column] = pd.NA\n",
    "\n",
    "for column in missing_columns_market2:\n",
    "    market2_orders[column] = pd.NA\n",
    "\n",
    "# Merge the datasets\n",
    "orders = pd.concat([market1_orders, market2_orders], ignore_index=True)\n",
    "\n",
    "# Replace \"-\" values with NaN\n",
    "orders.replace(\"-\", pd.NA, inplace=True)\n",
    "\n",
    "# Drop columns with empty/null rows or containing only \"-\" values\n",
    "def drop_empty_or_dash_columns(df):\n",
    "    return df.dropna(axis=1, how='all') \\\n",
    "             .loc[:, (df != '-').any()]  # Select columns where any value is not '-'\n",
    "\n",
    "orders = drop_empty_or_dash_columns(orders.copy())  # Avoid modifying original\n",
    "\n",
    "# Define the output folder\n",
    "output_folder = \"transformed_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Write the merged dataset to a new CSV file in the output folder\n",
    "merged_file_path = os.path.join(output_folder, \"orders.csv\")\n",
    "orders.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged dataset with standardized column names is saved in '{merged_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data with standardized columns saved to 'combined_deliveries.csv'\n"
     ]
    }
   ],
   "source": [
    "def get_standardized_column_names(file_names):\n",
    "    \"\"\"Gets standardized column names from the provided files.\"\"\"\n",
    "    standardized_columns = {}\n",
    "\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name, low_memory=False)\n",
    "\n",
    "        for original_column in df.columns:\n",
    "            # Example standardization logic (customize this)\n",
    "            new_column = original_column.lower().replace(\" \", \"_\")\n",
    "\n",
    "            # Handle duplicates (e.g., suffix market number)\n",
    "            if new_column in standardized_columns:\n",
    "                new_column += \"_market_\" + file_name.split(\" \")[0][-1] \n",
    "            standardized_columns[new_column] = original_column\n",
    "\n",
    "    return standardized_columns\n",
    "\n",
    "def combine_and_save_data(file_names, standardized_columns):\n",
    "    \"\"\"Combines data with standardized names and saves to a CSV file.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name, low_memory=False)\n",
    "        df.rename(columns=standardized_columns, inplace=True)\n",
    "        all_data.append(df)\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df.to_csv(\"combined_deliveries.csv\", index=False) \n",
    "# Main Execution\n",
    "file_names = [\"Market 1 Deliveries.csv\", \"Market 2 Deliveries.csv\"]\n",
    "\n",
    "standardized_columns = get_standardized_column_names(file_names)\n",
    "combine_and_save_data(file_names, standardized_columns)\n",
    "\n",
    "print(\"Combined data with standardized columns saved to 'combined_deliveries.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (7,9,12,14,16,19,30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "def update_data(df):\n",
    "    \"\"\"\n",
    "    Concatenates 'Agent ID' with 'Notes' and moves 'Agent Number' data to 'Agent ID'.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The updated DataFrame.\n",
    "    \"\"\"\n",
    "    # Concatenate Agent ID and Notes\n",
    "    df['Notes'] = df['Agent_ID'].astype(str) + ': ' + df['Notes']\n",
    "\n",
    "    df['Agent_ID'] = df['Agent_Name'] \n",
    "\n",
    "    df['Agent_Name'] = df['Distance(m)'] \n",
    "\n",
    "    df['Distance(m)'] = df['Total_Time_Taken(min)']\n",
    "\n",
    "    df['Total_Time_Taken(min)'] = df['Task_Status'] \n",
    "\n",
    "    df['Task_Status'] = df['Ref_Images'] \n",
    "\n",
    "    df['Ref_Images'] = df['Rating'] \n",
    "\n",
    "    df['Rating'] = df['Review'] \n",
    "\n",
    "    df['Review'] = df['Latitude'] \n",
    "\n",
    "    df['Latitude'] = df['Longitude'] \n",
    "\n",
    "    df['Longitude'] = df['Tags']\n",
    "\n",
    "    df['Tags'] = df['Promo_Applied'] \n",
    "\n",
    "    df['Promo_Applied'] = df['Custom_Template_ID']\n",
    "\n",
    "    df['Custom_Template_ID'] = df['Task_Details_QTY']\n",
    "\n",
    "    df['Task_Details_QTY'] = df['Task_Details_AMOUNT']\n",
    "\n",
    "    df['Task_Details_AMOUNT'] = df['Special_Instructions']\n",
    "\n",
    "    df['Special_Instructions'] = ''\n",
    "\n",
    "    df['Special_Instructions'] = df['Tip']\n",
    "\n",
    "    # Concatenate Tip with the existing Special_Instructions\n",
    "    df['Special_Instructions'] = df['Special_Instructions'].astype(str) + ': ' + df['Tip'] \n",
    "\n",
    "\n",
    "    # Clean currency symbols\n",
    "    df['Tip'] = df['Tip'].str.replace('KSh ', '')\n",
    "\n",
    "    # Fill missing 'Tip' with 'KSh 0.00' \n",
    "    df['Tip'] = df['Tip'].fillna('KSh 0.00')\n",
    "\n",
    "\n",
    "    df['Tip'] = df['Delivery_Charges']\n",
    "\n",
    "    df['Delivery_Charges'] = df['Discount']\n",
    "\n",
    "    df['Discount'] = df['Subtotal']\n",
    "\n",
    "    df['Subtotal'] = df['Payment_Type']\n",
    "\n",
    "    df['Payment_Type'] = df['Task_Category']\n",
    "\n",
    "    df['Task_Category'] = df['Earning']\n",
    "\n",
    "    df['Earning'] = df['Pricing']\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"combined_deliveries.csv\")\n",
    "\n",
    "# Update the DataFrame\n",
    "updated_df = update_data(df.copy())  # Operate on a copy\n",
    "\n",
    "updated_df.to_csv(\"updated_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (6,8,11,13,15,18,30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified data saved in 'transformed_data\\deliveries.csv'\n"
     ]
    }
   ],
   "source": [
    "def update_data(df):\n",
    "    \"\"\"\n",
    "    Concatenates 'Agent ID' with 'Notes' and moves 'Agent Number' data to 'Agent ID'.\n",
    "    Performs necessary string replacements in the 'Order_ID' column.\n",
    "    Replaces \"-\" values with NaN in each column.\n",
    "    Drops 'Unnamed: 30' and 'Unnamed: 31' columns.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The updated DataFrame.\n",
    "    \"\"\"\n",
    "    # Concatenate Tip with the existing Special_Instructions\n",
    "    df['Special_Instructions'] = df['Special_Instructions'].astype(str) + ': ' + df['Tip'] \n",
    "    \n",
    "    df['Special_Instructions'] = ''\n",
    "\n",
    "    df['Special_Instructions'] = df['Tip']\n",
    "\n",
    "    # Clean currency symbols\n",
    "    df['Tip'] = df['Tip'].str.replace('KSh ', '')\n",
    "\n",
    "    # Fill missing 'Tip' with 'KSh 0.00' \n",
    "    df['Tip'] = df['Tip'].fillna('KSh 0.00')\n",
    "\n",
    "    df['Tip'] = df['Delivery_Charges']\n",
    "\n",
    "    df['Delivery_Charges'] = df['Discount']\n",
    "\n",
    "    df['Discount'] = df['Subtotal']\n",
    "\n",
    "    df['Subtotal'] = df['Payment_Type']\n",
    "\n",
    "    df['Payment_Type'] = df['Task_Category']\n",
    "\n",
    "    df['Task_Category'] = df['Earning']\n",
    "\n",
    "    df['Earning'] = df['Pricing']\n",
    "\n",
    "    # Remove 'YR-' and ',0' from Order_ID\n",
    "    df['Order_ID'] = df['Order_ID'].str.replace('YR-', '').str.replace(',0', '')\n",
    "\n",
    "    # Replace \"-\" values with NaN in each column\n",
    "    df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "    # Drop 'Unnamed: 30' and 'Unnamed: 31' columns\n",
    "    df.drop(columns=['Unnamed: 30', 'Unnamed: 31'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"updated_data.csv\")\n",
    "\n",
    "# Define the output folder\n",
    "output_folder = \"transformed_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output file path within the output folder\n",
    "output_file_path = os.path.join(output_folder, \"deliveries.csv\")\n",
    "\n",
    "# Update the DataFrame\n",
    "updated_df = update_data(df.copy())  # Operate on a copy\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file in the output folder\n",
    "updated_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Modified data saved in '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (7,10,18,23,26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All markets data consolidated and saved in 'transformed_data\\all_markets_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the transformed data folder\n",
    "transformed_data_folder = \"transformed_data\"\n",
    "\n",
    "# List of files to read and consolidate\n",
    "files_to_read = [\"deliveries.csv\", \"customers.csv\", \"orders.csv\"]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Read and store DataFrames from each file\n",
    "for file_name in files_to_read:\n",
    "    file_path = os.path.join(transformed_data_folder, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes[file_name.split('.')[0]] = df\n",
    "    else:\n",
    "        print(f\"File '{file_name}' not found in '{transformed_data_folder}'.\")\n",
    "\n",
    "# Join DataFrames together\n",
    "all_markets_data = pd.concat(dataframes.values(), axis=1)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(transformed_data_folder, \"all_markets_data.csv\")\n",
    "\n",
    "# Write the consolidated DataFrame to a new CSV file\n",
    "all_markets_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"All markets data consolidated and saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All markets data consolidated and saved in 'transformed_data\\all_markets_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the transformed data folder\n",
    "transformed_data_folder = \"transformed_data\"\n",
    "\n",
    "# List of files to read and consolidate\n",
    "files_to_read = [\"deliveries.csv\", \"customers.csv\", \"orders.csv\"]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Read and store column names from each file\n",
    "column_names = {}\n",
    "for file_name in files_to_read:\n",
    "    file_path = os.path.join(transformed_data_folder, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path, nrows=0)  # Read only the header\n",
    "        column_names[file_name] = df.columns.tolist()\n",
    "    else:\n",
    "        print(f\"File '{file_name}' not found in '{transformed_data_folder}'.\")\n",
    "\n",
    "# Standardize column names and handle duplicates\n",
    "standardized_column_names = {}\n",
    "for file_name, cols in column_names.items():\n",
    "    prefix = file_name.split('.')[0] + \"_\"\n",
    "    standardized_cols = [prefix + col.lower().replace(\" \", \"_\") for col in cols]\n",
    "    standardized_column_names[file_name.split('.')[0]] = standardized_cols\n",
    "\n",
    "# Create a new DataFrame with standardized column names\n",
    "all_markets_data = pd.DataFrame()\n",
    "\n",
    "# Copy data from original files into the new DataFrame\n",
    "for file_name in files_to_read:\n",
    "    df = pd.read_csv(os.path.join(transformed_data_folder, file_name), dtype={'ID': object})\n",
    "    df.columns = standardized_column_names[file_name.split('.')[0]]\n",
    "    all_markets_data = pd.concat([all_markets_data, df], axis=1)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(transformed_data_folder, \"all_markets_data.csv\")\n",
    "\n",
    "# Write the consolidated DataFrame to a new CSV file\n",
    "all_markets_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"All markets data consolidated and saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified data saved in 'data\\markets_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory containing the consolidated data file\n",
    "consolidated_data_folder = \"transformed_data\"\n",
    "\n",
    "# Define the file name of the consolidated data\n",
    "consolidated_file_name = \"all_markets_data.csv\"\n",
    "\n",
    "# Define the output folder for the modified data\n",
    "output_folder = \"data\"\n",
    "\n",
    "# Define the output file name\n",
    "output_file_name = \"markets_data.csv\"\n",
    "\n",
    "# Read the consolidated data file\n",
    "consolidated_data = pd.read_csv(os.path.join(consolidated_data_folder, consolidated_file_name))\n",
    "\n",
    "# Define the columns that may have decimal values\n",
    "columns_to_check = ['deliveries_order_id', 'customers_customer_id', 'orders_order_id', 'orders_transaction_id', 'orders_customer_id', 'orders_merchant_id']\n",
    "\n",
    "# Remove '.0' from the values in the specified columns\n",
    "for column in columns_to_check:\n",
    "    consolidated_data[column] = consolidated_data[column].astype(str).str.replace(r'\\.0', '', regex=True)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "consolidated_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Modified data saved in '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers of markets_data.csv:\n",
      "deliveries_task_id\n",
      "deliveries_order_id\n",
      "deliveries_relationship\n",
      "deliveries_team_name\n",
      "deliveries_task_type\n",
      "deliveries_notes\n",
      "deliveries_agent_id\n",
      "deliveries_agent_name\n",
      "deliveries_distance(m)\n",
      "deliveries_total_time_taken(min)\n",
      "deliveries_task_status\n",
      "deliveries_ref_images\n",
      "deliveries_rating\n",
      "deliveries_review\n",
      "deliveries_latitude\n",
      "deliveries_longitude\n",
      "deliveries_tags\n",
      "deliveries_promo_applied\n",
      "deliveries_custom_template_id\n",
      "deliveries_task_details_qty\n",
      "deliveries_task_details_amount\n",
      "deliveries_special_instructions\n",
      "deliveries_tip\n",
      "deliveries_delivery_charges\n",
      "deliveries_discount\n",
      "deliveries_subtotal\n",
      "deliveries_payment_type\n",
      "deliveries_task_category\n",
      "deliveries_earning\n",
      "deliveries_pricing\n",
      "customers_customer_id\n",
      "customers_last_used_platform\n",
      "customers_is_blocked\n",
      "customers_created_at\n",
      "customers_language\n",
      "customers_outstanding_amount\n",
      "customers_loyalty_points\n",
      "customers_number_of_employees\n",
      "orders_order_id\n",
      "orders_order_status\n",
      "orders_category_name\n",
      "orders_sku\n",
      "orders_quantity\n",
      "orders_unit_price\n",
      "orders_cost_price\n",
      "orders_total_cost_price\n",
      "orders_total_price\n",
      "orders_order_total\n",
      "orders_sub_total\n",
      "orders_remaining_balance\n",
      "orders_payment_method\n",
      "orders_transaction_id\n",
      "orders_currency_symbol\n",
      "orders_customer_id\n",
      "orders_merchant_id\n",
      "orders_description\n",
      "orders_distance_(in_km)\n",
      "orders_order_time\n",
      "orders_pickup_time\n",
      "orders_delivery_time\n",
      "orders_ratings\n",
      "orders_reviews\n",
      "orders_order_preparation_time\n",
      "orders_redeemed_loyalty_points\n",
      "orders_consumed_loyalty_points\n",
      "orders_flat_discount\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/markets_data.csv\")\n",
    "\n",
    "print(\"Column headers of markets_data.csv:\")\n",
    "for column in df.columns:\n",
    "    print(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
